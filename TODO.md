# TODO â€” Impractical PNGTuber With Memes

> **âš ï¸ IMPORTANT PROMPT FOR ALL AGENTS / CONTRIBUTORS:**
>
> 1. ALWAYS UPDATE THIS LOG when making any change, fix, or progress -- no matter how small.
> 2. ALWAYS SHOW DATES in the format YYYY-MM-DD HH:MM (24-hour, UTC+7 Jakarta time).
> 3. NEVER DELETE PROGRESS -- even if a task is completed, keep the log entry and mark it as âœ… DONE.
> 4. ADD NEW ENTRIES AT THE TOP of each section's log (newest first).
> 5. When starting work on any task, update its status to ðŸ”„ IN PROGRESS.
> 6. When completing a task, update its status to âœ… DONE and add a summary of what was done.
> 7. If a task is blocked, mark it as ðŸš« BLOCKED with a reason.
> 8. Reference commit hashes where applicable.

## Change Log
- 2026-02-15 09:49: âœ… DONE Updated log instructions to use numbered list.
- 2026-02-15 09:47: âœ… DONE Added standard log instructions and Change Log section.

> Created: 2026-02-15
> Status: ðŸŸ¡ Phase 3: Coding "Waduh" Detector

---

## Phase 0: Environment Setup
- [x] Install Python 3.11 (via winget)
- [x] Create virtual environment (`python -m venv venv`)
- [x] Install core dependencies (mediapipe, opencv, etc.)


- [ ] Install core dependencies:
  ```
  pip install mediapipe opencv-python numpy Pillow pyvirtualcam
  ```
- [ ] Verify OBS Studio is installed (needed for virtual camera backend on Windows)
- [ ] Test webcam access with a simple OpenCV script

---

## Phase 1: Mirror Test (Skeleton Viewer) ðŸªž
> **Goal:** See your skeleton in real-time. Confirm camera + lighting works.

- [ ] Create `scripts/1_mirror_test.py`
  - [ ] Open webcam with OpenCV
  - [ ] Run MediaPipe Holistic on each frame
  - [ ] Draw Pose skeleton (33 pts) on screen
  - [ ] Draw Hand landmarks (21 pts per hand) on screen
  - [ ] Draw Face Mesh (468 pts) on screen
  - [ ] Display FPS counter
  - [ ] Press `Q` to quit
- [ ] **TEST:** Can you see all 3 layers (body, hands, face) clearly?
- [ ] **TEST:** Move around â€” does the skeleton follow smoothly?

---

## Phase 2: Pose Recorder (Snapshot Tool) ðŸ“¸
> **Goal:** Save your "meme poses" as JSON data files.

- [ ] Create `scripts/2_record_pose.py`
  - [ ] Show live skeleton (reuse Phase 1 code)
  - [ ] Display instructions on screen ("Strike a pose, press SPACE to save")
  - [ ] On SPACE press:
    - [ ] Capture all landmark coordinates (Pose + Hands + Face)
    - [ ] Normalize landmarks (relative to body center, scale-independent)
    - [ ] Calculate key joint angles (elbows, shoulders, wrists)
    - [ ] Save to `poses/[meme_name].json`
  - [ ] Allow typing a meme name via console input
  - [ ] Press `Q` to quit
- [ ] Create `poses/` directory
- [ ] **TEST:** Record all 7 meme poses and verify JSON files are saved

---

## Phase 3: Gesture Engine (The Brain) ðŸ§ 
> **Goal:** Real-time comparison of live skeleton vs saved poses.

- [ ] Create `src/gesture_engine.py` (Started)
  - [ ] Implement rule-based detectors for each meme:


### Per-Meme Detection Rules

| # | Meme | Rule | Priority |
|---|------|------|----------|
| 1 | **FreakyCat** (Tongue Out) | Face mesh: mouth open ratio > threshold | ðŸ”´ Hard |
| 2 | **MewingCat** (Shhh) | Hand index tip near face mouth + 1 finger extended | ðŸ”´ Hard |
| 3 | **MilesMorales** (Hands Behind Head) | Both wrists above & behind ears | ðŸŸ¢ Easy |
| 4 | **Pointing At Self** | Index finger extended toward own chest | ðŸŸ¡ Medium |
| 5 | **SneakyGolem** (Hand on Mouth) | Palm near mouth + multiple fingers extended | ðŸŸ¡ Medium |
| 6 | **Waduh** (Hand on Head) | One wrist above nose, palm down | ðŸŸ¢ Easy |
| 7 | **CatLaugh** (Point at Camera) | Index extended + smallest Z-depth | ðŸ”´ Hard |

  - [ ] Implement confidence scoring (0.0 - 1.0) for each gesture
  - [ ] Implement cooldown timer (prevent flickering between memes)
  - [ ] Implement "idle" state (no gesture matched â†’ default image)
  - [ ] **TEST:** Print detected gesture name to console in real-time

---

## Phase 4: Image Switcher (The Face) ðŸŽ­
> **Goal:** Display the correct meme image when a gesture is detected.

- [ ] Create `src/image_switcher.py`
  - [ ] Load all meme images from `assets/memes/`
  - [ ] Handle PNG (static) and GIF (animated) formats
  - [ ] Resize meme images to match virtual camera resolution (e.g., 1280x720)
  - [ ] On gesture match â†’ display corresponding meme
  - [ ] On no match â†’ display idle/default image
  - [ ] Smooth transition (fade or instant swap â€” TBD)
- [ ] Create/find a default idle image (`assets/memes/idle.png`)
- [ ] **TEST:** Manually trigger each meme and verify it displays correctly

---

## Phase 5: Virtual Camera Output ðŸ“¹
> **Goal:** Make OBS/Discord/Zoom see the meme images as your "webcam."

- [ ] Create `src/virtual_cam.py`
  - [ ] Initialize `pyvirtualcam` with OBS backend
  - [ ] Set resolution to 1280x720 @ 20 FPS
  - [ ] Pipe the output from Image Switcher to virtual cam
  - [ ] Handle color space conversion (BGR â†’ RGB for pyvirtualcam)
- [ ] **TEST:** Open Discord/Zoom â†’ check if "OBS Virtual Camera" shows meme images
- [ ] **TEST:** Open OBS â†’ add "Video Capture Device" â†’ select virtual cam

---

## Phase 6: Main App (All Together) ðŸš€
> **Goal:** Single script that runs everything.

- [ ] Create `main.py`
  - [ ] Initialize webcam
  - [ ] Initialize MediaPipe Holistic
  - [ ] Initialize Gesture Engine (load poses)
  - [ ] Initialize Image Switcher (load memes)
  - [ ] Initialize Virtual Camera
  - [ ] Main loop:
    1. Read webcam frame
    2. Process with MediaPipe â†’ get landmarks
    3. Pass landmarks to Gesture Engine â†’ get matched gesture
    4. Pass gesture to Image Switcher â†’ get meme image
    5. Send meme image to Virtual Camera
    6. (Optional) Show debug window with skeleton overlay
  - [ ] Press `Q` to quit
  - [ ] Clean up resources on exit

---

## Phase 7: Polish & QoL âœ¨
> **Goal:** Make it actually usable for streaming.

- [ ] Add config file (`config.json`) for:
  - [ ] Webcam device index
  - [ ] Resolution
  - [ ] Confidence thresholds per gesture
  - [ ] Cooldown timer duration
  - [ ] Debug mode on/off
- [ ] Add on-screen overlay showing current detected gesture (debug mode)
- [ ] Add sound effects on gesture trigger (optional, fun)
- [ ] Handle edge cases:
  - [ ] No webcam found
  - [ ] MediaPipe fails to detect (poor lighting)
  - [ ] Multiple gestures detected simultaneously (priority system)
- [ ] GIF animation support (frame-by-frame playback for animated memes)
- [ ] Performance profiling and optimization

---

## Phase 8 (Future): GUI & Ease of Use ðŸŽ¨
> **Goal:** Make it easy for non-technical users.

- [ ] Simple GUI (Tkinter or web-based) with:
  - [ ] Live preview window
  - [ ] "Record New Pose" button
  - [ ] Drag-and-drop meme image upload
  - [ ] Gesture sensitivity sliders
  - [ ] Start/Stop toggle
- [ ] Package as standalone `.exe` (PyInstaller or similar)

---

## File Structure (Target)

```
Impractical_PNG-tuber_With_Memes/
â”œâ”€â”€ main.py                          # Entry point
â”œâ”€â”€ config.json                      # Settings
â”œâ”€â”€ requirements.txt                 # pip dependencies
â”œâ”€â”€ README.md                        # Project overview
â”œâ”€â”€ RESEARCH_AND_REFERENCE.md        # Tech research
â”œâ”€â”€ TODO.md                          # This file
â”œâ”€â”€ memes_list.md                    # Meme catalog
â”‚
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ memes/
â”‚       â”œâ”€â”€ idle.png                 # Default "no gesture" image
â”‚       â”œâ”€â”€ FreakyCat(Tongue_Out).jpg
â”‚       â”œâ”€â”€ MewingCat(Finger_On_Mouth_Vertical).gif
â”‚       â”œâ”€â”€ MilesMorales(Two_Hands_Behind_Head).png
â”‚       â”œâ”€â”€ Pointing_FInger_At_Self.png
â”‚       â”œâ”€â”€ SneakyGolem(Holding_Mouth_With_One_Hand).jpg
â”‚       â”œâ”€â”€ Waduh(One_Hand_On_Top_Of_Head).jpg
â”‚       â””â”€â”€ CatLaugh(Pointing_Finger_At_You).gif
â”‚
â”œâ”€â”€ poses/                           # Saved pose snapshots (JSON)
â”‚   â”œâ”€â”€ freaky_cat.json
â”‚   â”œâ”€â”€ mewing_cat.json
â”‚   â”œâ”€â”€ miles_morales.json
â”‚   â”œâ”€â”€ pointing_self.json
â”‚   â”œâ”€â”€ sneaky_golem.json
â”‚   â”œâ”€â”€ waduh.json
â”‚   â””â”€â”€ cat_laugh.json
â”‚
â”œâ”€â”€ scripts/                         # Development/testing scripts
â”‚   â”œâ”€â”€ 1_mirror_test.py             # Phase 1: See your skeleton
â”‚   â””â”€â”€ 2_record_pose.py             # Phase 2: Save pose snapshots
â”‚
â””â”€â”€ src/                             # Core modules
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ gesture_engine.py            # Phase 3: Gesture detection logic
    â”œâ”€â”€ image_switcher.py            # Phase 4: Meme display logic
    â””â”€â”€ virtual_cam.py               # Phase 5: Virtual camera output
```

---

## Priority Order (What to build first)

1. ðŸŸ¢ **Phase 0** â€” Setup (5 min)
2. ðŸŸ¢ **Phase 1** â€” Mirror Test (30 min) â€” *Proves the AI works*
3. ðŸŸ¡ **Phase 3** â€” Gesture Engine for EASY memes first:
   - `Waduh` (hand on head) â€” easiest to detect
   - `MilesMorales` (hands behind head) â€” second easiest
4. ðŸŸ¡ **Phase 4** â€” Image Switcher (show the meme on screen)
5. ðŸŸ¡ **Phase 5** â€” Virtual Camera (so OBS can see it)
6. ðŸ”´ **Phase 3 continued** â€” Hard memes:
   - `SneakyGolem` (hand on mouth)
   - `Pointing At Self` (finger direction)
   - `MewingCat` (shhh â€” finger on lips)
   - `FreakyCat` (tongue out)
   - `CatLaugh` (pointing at camera)
7. ðŸŸ¢ **Phase 6** â€” Combine everything into `main.py`
8. âšª **Phase 7-8** â€” Polish (later)

---

## Notes
- Skip Phase 2 (Pose Recorder) initially. Start with hardcoded rules for the easy memes.
- Only build the recorder if the rule-based approach becomes too tedious.
- GIF support can wait â€” static frame display is fine for the prototype.
- Every phase should be independently testable before moving to the next.
